---
title: MCP Server
description: Use memories.sh with any MCP-compatible client.
---

memories.sh includes a built-in MCP (Model Context Protocol) server that exposes your memories directly to any compatible AI agent or client.

**MCP Endpoint**

```txt title="Endpoint URL"
https://memories.sh/api/mcp
```

## Cloud MCP (Recommended)

For the best experience, use our hosted MCP endpoint. Your memories sync across all devices and you don't need the CLI running locally.

### 1. Get Your API Key

Sign up and get your API key from the [dashboard](/app), or run:

```bash
memories login
```

### 2. Configure Your Tool

Add the memories MCP server to your tool's configuration. The config is the same for most tools:

```json
{
  "mcpServers": {
    "memories": {
      "url": "https://memories.sh/api/mcp",
      "headers": {
        "Authorization": "Bearer YOUR_API_KEY"
      }
    }
  }
}
```

Replace `YOUR_API_KEY` with your key from the [dashboard](/app).

#### Config file locations

| Tool | Config Path |
|------|-------------|
| Cursor | `.cursor/mcp.json` or `~/.cursor/mcp.json` |
| Claude Code | `.mcp.json` or `~/.mcp.json` |
| Claude Desktop | `~/Library/Application Support/Claude/claude_desktop_config.json` |
| Windsurf | `.windsurf/mcp.json` |
| VS Code | `.vscode/mcp.json` (uses `servers` instead of `mcpServers`) |
| v0 / Web | Paste config directly into the MCP settings |

---

## Local MCP (Self-Hosted)

For local-only use without cloud sync, run the MCP server locally. This is useful for air-gapped environments or if you prefer keeping data entirely on your machine.

### Quick Setup

Run `memories init` to automatically detect and configure your tools:

```bash
memories init
```

### Manual Configuration

Start the local server:

```bash
memories serve
```

Then configure your tool to spawn it:

```json
{
  "mcpServers": {
    "memories": {
      "command": "npx",
      "args": ["-y", "@memories.sh/cli", "serve"]
    }
  }
}
```

Use the same config file locations as above. For VS Code, use `servers` instead of `mcpServers`.

---

## Available Tools

The MCP server exposes these tools to connected clients:

| Tool | Description |
|------|-------------|
| `get_context` | Get rules and relevant memories for the current task |
| `add_memory` | Store a new memory (rule, decision, fact, or note) |
| `search_memories` | Full-text search across memory content |
| `list_memories` | List recent memories, optionally filtered |
| `get_rules` | Get all active rules |
| `edit_memory` | Update an existing memory |
| `forget_memory` | Soft-delete a memory |

### Example: Adding a memory via MCP

When your AI agent learns something important, it can save it:

```
Tool: add_memory
Arguments: {
  "content": "The API rate limit is 100 requests per minute",
  "type": "fact",
  "tags": ["api", "limits"]
}
```

### Example: Getting context

```
Tool: get_context
Arguments: {
  "query": "authentication flow"
}
```

Returns all active rules plus memories relevant to the query.

## Cloud vs Local: When to Use Each

| Feature | Cloud MCP | Local MCP |
|---------|-----------|-----------|
| Sync across devices | ✓ | ✗ |
| Works offline | ✗ | ✓ |
| No local install needed | ✓ | ✗ |
| Air-gapped environments | ✗ | ✓ |
| Web-based tools (v0) | ✓ | ✗ |

**Use Cloud MCP** if you work across multiple machines or want the simplest setup.

**Use Local MCP** if you need offline access, work in air-gapped environments, or prefer keeping all data on your machine.
