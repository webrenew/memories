---
title: Getting Started
description: Install memories.sh, add your first memories, and generate config files for your AI coding tools.
---

## Installation

Install the CLI globally:

```bash
pnpm add -g @memories.sh/cli
```

Verify the installation:

```bash
memories --version
```

<Callout>
The semantic search model (~100MB) downloads on first use and runs entirely locally — no API calls, no data leaves your machine.
</Callout>

## Initialize

Navigate to a git repository and initialize memories:

```bash
cd your-project
memories init
```

The `init` command does several things automatically:

1. **Creates the local database** at `~/.config/memories/local.db`
2. **Detects installed AI tools** (Cursor, Claude Code, Windsurf, VS Code)
3. **Configures MCP** for each detected tool
4. **Generates instruction files** with your existing memories

Example output:

```
[1/4] Setting up local storage...
  Database: ~/.config/memories/local.db
[2/4] Detecting scope...
✓ Project scope detected
  Project: github.com/your-org/your-project
[3/4] Detecting AI coding tools...
  Cursor ✓ MCP ○ Rules
  Claude Code ○ MCP ✓ Rules
  
✓ Cursor: MCP already configured
✓ Claude Code: MCP configured → .mcp.json

✓ Cursor: Generated .cursor/rules/memories.mdc
[4/4] Finalizing...
```

### Init Options

```bash
# Skip automatic MCP configuration
memories init --skip-mcp

# Skip generating instruction files  
memories init --skip-generate

# Auto-confirm all prompts
memories init -y

# Initialize with starter rules
memories init --rule "Use TypeScript strict mode" --rule "Prefer pnpm"

# Initialize global memories (apply to all projects)
memories init --global
```

## Add Your First Memory

Memories come in four types: **rules**, **decisions**, **facts**, and **notes**.

### Rules

Rules are always-active coding standards that should be followed:

```bash
memories add --rule "Always use early returns to reduce nesting"
memories add --rule "Use pnpm as the package manager"
memories add --rule "Prefer named exports over default exports"
```

### Decisions

Decisions capture the "why" behind architectural choices:

```bash
memories add --decision "Chose Tailwind CSS over styled-components for utility-first approach and smaller bundle size"
memories add --decision "Using Supabase for auth because it has built-in RLS and a generous free tier"
```

### Facts

Facts store project-specific knowledge:

```bash
memories add --fact "API rate limit is 100 requests per minute per user"
memories add --fact "The main database is PostgreSQL 15 hosted on Supabase"
```

### Notes

Notes are general-purpose memories (the default type):

```bash
memories add "The legacy API will be deprecated in Q3 2026"
```

## Tag Your Memories

Tags help organize and filter memories:

```bash
memories add --rule "Use React Server Components by default" --tags "react,architecture"
memories add --fact "Stripe webhook secret is in STRIPE_WEBHOOK_SECRET env var" --tags "stripe,config"
```

## Generate Config Files

Generate native rule files for your AI tools:

```bash
# Generate for a specific tool
memories generate cursor
memories generate claude
memories generate copilot

# Generate for all supported tools at once
memories generate all
```

Supported targets: `cursor`, `claude`, `agents`, `copilot`, `windsurf`, `cline`, `roo`, `gemini`.

Each target writes to its standard location:

| Target | Output Path |
|--------|-------------|
| `cursor` | `.cursor/rules/memories.mdc` |
| `claude` | `CLAUDE.md` |
| `agents` | `AGENTS.md` |
| `copilot` | `.github/copilot-instructions.md` |
| `windsurf` | `.windsurf/rules/memories.md` |
| `cline` | `.clinerules/memories.md` |
| `roo` | `.roo/rules/memories.md` |
| `gemini` | `GEMINI.md` |

## Search Your Memories

memories.sh supports both keyword and semantic search:

```bash
# Keyword search (FTS5 with BM25 ranking)
memories search "authentication"

# Semantic search (AI-powered, finds related concepts)
memories search "how to handle user login" --semantic
```

<Callout>
**First-time semantic search** downloads the embedding model (~100MB) to `~/.cache/memories/models/`. This happens once and runs entirely locally — no API calls, no data leaves your machine.
</Callout>

To generate embeddings for existing memories:

```bash
memories embed
```

## Use the MCP Server

The MCP server exposes your memories directly to AI tools. If you ran `memories init`, MCP is already configured for your detected tools.

To start the server manually:

```bash
memories serve
```

MCP gives your AI tools live access to:
- Search and recall memories
- Add new memories during conversations
- Access project-specific context

See the [MCP Server](/docs/mcp-server) guide for details.

## Sync Config Files Across Machines

Beyond memories, you can sync your AI tool configuration files:

```bash
# Import global configs (skills, commands, rules)
memories files ingest

# See what would be imported
memories files ingest --dry-run

# Apply synced files to a new machine
memories files apply --global --force
```

This syncs files from `.agents/`, `.claude/`, `.cursor/`, `.codex/`, `.windsurf/`, and other tool directories. See [Files Sync](/docs/cli/files) for details.

## Next Steps

- [CLI Reference](/docs/cli) — Complete command documentation
- [Memory Types and Scopes](/docs/concepts/memory-types) — Understanding the type system
- [MCP Server](/docs/mcp-server) — Connect memories to any MCP-compatible tool
- [Files Sync](/docs/cli/files) — Sync config files across machines
- [Cloud Sync](/docs/cloud-sync) — Multi-device sync with Pro
