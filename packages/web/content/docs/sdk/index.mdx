---
title: TypeScript SDK
description: Wire persistent memory into AI apps with two packages.
---

The memories.sh SDK gives AI applications persistent memory through two packages:

| Package | What it does |
|---------|-------------|
| `@memories.sh/ai-sdk` | Middleware + tools for the [AI SDK](https://ai-sdk.dev/) |
| `@memories.sh/core` | Standalone client for any LLM framework |

## Transport Model (Important)

- SDK default: **HTTP API** via `/api/sdk/v1/*`
- Optional: **MCP transport** via JSON-RPC at `/api/mcp`
- Not used by SDK runtime: **CLI commands** (`memories ...`) are separate tooling

`MemoriesClient` resolves `transport: "auto"` to HTTP API unless `baseUrl` points at `/api/mcp`.

## Three Tiers of Integration

| Tier | Pattern | DX | When to use |
|------|---------|-----|------------|
| **Middleware** | Auto-inject context into every prompt | 2 lines | Default — "it just works" |
| **Tools** | LLM decides when to read/write | 3-5 lines | Agent loops that manage their own memory |
| **Client** | Dev manually fetches context | 10+ lines | Custom integrations, non-AI-SDK apps |

## Scoping Model

- `tenantId`: AI SDK Project (security/database boundary)
- `userId`: end-user scope inside `tenantId`
- `projectId`: optional git/repository context filter (not an auth boundary)

When tenant auto-provision is enabled on your server, first requests for a new `tenantId` can provision its Turso database automatically.

`tenantId` and `projectId` are intentionally different:

- `tenantId` chooses the memory database (security boundary)
- `projectId` narrows retrieval inside that database (context boundary)

Start with [AI SDK Projects](/docs/sdk/projects) if you want the dashboard-first flow.

## Quick Start

### Dashboard setup (recommended first)

1. Open **Dashboard → AI SDK Projects**.
2. Generate a `mem_...` API key.
3. Use trusted backend-derived `tenantId` values. Databases auto-provision on first use when enabled.
4. Configure tenant overrides only if you need explicit DB attachment/provisioning control.

### Install

```bash
pnpm add @memories.sh/ai-sdk
```

Set your API key:

```bash
export MEMORIES_API_KEY=mem_xxx
```

### Middleware (recommended)

Two lines to add memory to any model:

```typescript
import { generateText, wrapLanguageModel } from "ai"
import { openai } from "@ai-sdk/openai"
import { memoriesMiddleware } from "@memories.sh/ai-sdk"

const model = wrapLanguageModel({
  model: openai("gpt-4o"),
  middleware: memoriesMiddleware({ tenantId: "acme-prod" }),
})

const { text } = await generateText({
  model,
  prompt: "How should I handle auth in this project?",
})
// Model automatically sees relevant rules + memories in its system prompt
```

### Tools (for agent loops)

When the LLM should manage its own memory:

```typescript
import { generateText, stepCountIs } from "ai"
import { memoriesTools, memoriesSystemPrompt } from "@memories.sh/ai-sdk"

const { text } = await generateText({
  model: openai("gpt-4o"),
  system: memoriesSystemPrompt(),
  tools: memoriesTools({ tenantId: "acme-prod" }),
  stopWhen: stepCountIs(5),
  prompt: userMessage,
})
```

### Core Client (no AI SDK)

Use with any LLM SDK:

```typescript
import { MemoriesClient } from "@memories.sh/core"

const client = new MemoriesClient({ apiKey: "mem_xxx", tenantId: "acme-prod" })
const { rules, memories } = await client.context.get({
  query: "deployment process",
  userId: "user_123",
  projectId: "github.com/acme/platform",
  mode: "all",
})

const response = await anthropic.messages.create({
  model: "claude-sonnet-4-5-20250929",
  system: client.buildSystemPrompt({ rules, memories }),
  messages: [{ role: "user", content: userMessage }],
})
```

## Management APIs (Copy-Paste)

### `MemoriesClient.management.*`

```typescript
import { MemoriesClient } from "@memories.sh/core"

const client = new MemoriesClient({
  apiKey: process.env.MEMORIES_API_KEY,
  baseUrl: "https://memories.sh",
  transport: "sdk_http",
})

const keyStatus = await client.management.keys.get()
const rotatedKey = await client.management.keys.create({
  expiresAt: "2027-01-01T00:00:00.000Z",
})
const revoked = await client.management.keys.revoke()

const tenantMappings = await client.management.tenants.list()
const upsertedTenant = await client.management.tenants.upsert({
  tenantId: "acme-prod",
  mode: "provision",
})
const disabledTenant = await client.management.tenants.disable("acme-prod")

void [keyStatus, rotatedKey, revoked, tenantMappings, upsertedTenant, disabledTenant]
```

### `memoriesManagement()`

```typescript
import { memoriesManagement } from "@memories.sh/ai-sdk"

const management = memoriesManagement({
  apiKey: process.env.MEMORIES_API_KEY,
  baseUrl: "https://memories.sh",
})

const keyStatus = await management.keys.get()
const rotatedKey = await management.keys.create({
  expiresAt: "2027-01-01T00:00:00.000Z",
})
const revoked = await management.keys.revoke()

const tenantMappings = await management.tenants.list()
const upsertedTenant = await management.tenants.upsert({
  tenantId: "acme-prod",
  mode: "provision",
})
const disabledTenant = await management.tenants.disable("acme-prod")

void [keyStatus, rotatedKey, revoked, tenantMappings, upsertedTenant, disabledTenant]
```

## Availability

The SDK is available on the Enterprise plan. [Contact us](mailto:hello@memories.sh) to get started.

## Next Steps

- [AI SDK Projects](/docs/sdk/projects) — dashboard onboarding for solo devs and teams
- [Middleware reference](/docs/sdk/middleware) — `memoriesMiddleware()` config and composability
- [SaaS auth routing](/docs/sdk/saas-auth-routing) — derive trusted `tenantId`/`userId` in backend routes
- [Tools reference](/docs/sdk/tools) — `memoriesTools()` bundle and individual tools
- [Core Client reference](/docs/sdk/client) — `MemoriesClient` class API
- [SDK endpoint contract](/docs/sdk/endpoint-contract) — HTTP routes, response envelopes, and error model
- [Memory Graph architecture](/docs/sdk/graph-architecture) — extraction, storage, retrieval, and rollout guardrails
- [Graph default-on rollout](/docs/sdk/graph-default-on-rollout) — SLO gates, baseline gap tracking, and autopilot policy
- [Graph operations runbook](/docs/sdk/graph-operations-runbook) — production checks, incident response, and safe rollout flow
- [Live baseline report](https://github.com/webrenew/memories/blob/main/reports/graph-rollout/latest.md) — latest rollout baseline snapshot and blocker/recommendation trends
